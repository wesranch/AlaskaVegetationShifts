---
title: "Random Forest Modeling CAFI Data"
author: "Wesley Rancher, Hana Matsumoto"
date: "2024-08-13"
output: html_document
editor_options:
    chunk_output_type: console
---

## The code takes outputs from Google Earth Engine in the form of annual Landsat derived predictor 
## variable raster stacks. Accompanied with csvs of pv pixel values at fia plots. This data is used
## to run random forest models and make spatial predictions of species biomass and basal area.

# The steps for replicating the workflow are:
1. Acquire remote sensing data from GEE and save as CSV
2. If your CSV has NA or missing data maybe predictive imputation or roughfix to remove NAs
3. Run your cleaned CSV from step 2 through Boruta to get a refined model formula (feature wrapping)
4. Feed this formula into a random forest recipe and further parameterize your RF model
5. Make spatial predictions if you have rasters with the same predictor variables

```{r Libraries}
knitr::opts_chunk$set(echo = FALSE, eval = FALSE, fig.width = 6, fig.align = 'center')
library(dplyr)
library(terra)
library(randomForest)
library(stringr)
library(tidyr)
library(sf)
library(tidymodels)
library(ggplot2)
library(vip)
library(usemodels)
library(doParallel) #parallel processing
library(parsnip)
library(xgboost)
```

## Set up the response variable 

```{r Read in reponse variable dataframes}
setwd("E:/MS-Research/alaska/")
spp_biomass_plots <- read.csv("data/input/cafi/BIOMASS_AT_SITES_2015_V2.csv")
spp_biomass_plots <- spp_biomass_plots %>%
  select(-Bio.g_Sum)%>%
  group_by(Species) %>%
  pivot_wider(names_from = Species, values_from = Bio.g.m2)
colnames(spp_biomass_plots) <- gsub(" ", "_", colnames(spp_biomass_plots)) #remove spaces from spp names
spp_biomass_plots[is.na(spp_biomass_plots)] <- 0 #replace NAs in biomass with 0.0


###### basal area
spp_basal_area_plots <- read.csv("data/input/cafi/BASAL_AREA_AT_SITES_2015.csv")
spp_basal_area_plots[is.na(spp_basal_area_plots)] <- 0 #replace NAs in basal area with 0.0
```

# Read in CSVs output from GEE Sampling

```{r Iterate Over PV CSVs and Store Pred Var DF}
# read in extracted predictors from gee
output_dir <- "data/output/csv/cleaned/GEE_Sampling_Data_BiomassLandisRegion/"
extracted_dfs <- list.files(output_dir, pattern = "PixelVals_Interior_.*\\.csv", full.names = TRUE)
# if iterating
pv_dfs_all_years <- list()
for (i in seq_along(extracted_dfs)){
  extracted_df <- read.csv(extracted_dfs[[i]])
  pv_dataframe <- left_join(spp_biomass_plots, 
                            extracted_df, by = "PSP") #join where we have tree meas.
  pv_dataframe <- pv_dataframe %>%
    select( -c(1:4, 10,13)) %>%#change this based on structure of df
    rename(y = Latitude.y, x = Longitude.y)
  
  # pv_dataframe <- pv_dataframe %>%
  #   select( -c(1, 7:79, 82)) %>%#change this based on structure of df
  #   rename(y = Latitude.y, x = Longitude.y)
  

  pv_dfs_all_years[[i]] <- pv_dataframe
  glimpse(pv_dfs_all_years[[i]])
}
```

## Read in tiffs output by GEE

```{r Read in GEE Ouput Maps}
#read in rasters from gee
gee_dir <- "data/output/gee/"
list_of_files <- list.files(gee_dir, pattern = "FullComp_Dalton", full.names = TRUE)
pv_composites <- lapply(list_of_files, rast)

#define function for creating xy bands
add_xy_bands <- function (raster) {
  
  raster_df <- as.data.frame(raster, xy = TRUE)
  
  xrast <- rast(ncol = ncol(raster), nrow = nrow(raster), crs = crs(raster))
  yrast <- rast(ncol = ncol(raster), nrow = nrow(raster), crs = crs(raster))
  
  values(xrast) <- raster_df$x
  values(yrast) <- raster_df$y
  names(xrast) <- "x"
  names(yrast) <- "y"
  
  # set ext and add bands
  ext(xrast) <- ext(raster)
  ext(yrast) <- ext(raster)
  pv_rast_xy <- c(raster, xrast, yrast)
  return(pv_rast_xy)
}

#apply the function to the list of rasters
pv_composites_all_bands <- lapply(pv_composites, add_xy_bands)
```

## For each df we isolate the dependent variable (each tree spp), and tune the model and output results. Additionally, we 
## make spatial predictions for each dependent variable at each time step. Should be a total of 144 maps.

```{r Tidy Models Workflows RF}
# n_cores <- detectCores() -2 #leave free cores
# clus <- makeCluster(n_cores)
# registerDoParallel(clus)
out_dir_metrics <- "data/output/csv/cleaned/Biomass_RF_Model_Run_Results/"
rf_models_all_years <- list()
rf_model_metrics <- list()
importance_plots_all_years <- list()
importance_scores_all_years <- list()
model_accuracy_all_years <- list()
predRasters_all_years <- list()
pv_fits_all_years <- list()

# loop over each pv dataframe and drop highly correlated vars and Random Forest
# foreach(year_id = seq_along(pv_dfs_all_years), .combine = 'list', 
#                     .packages = c("tidyverse", "tidymodels", "randomForest", "dplyr", "vip")) %dopar% {
years <- 2000:2023
index <- 1:24
for (i in seq_along(years))  {
  year <- years[i]  
  list_id <- index[i]
  pv_dataframe <- pv_dfs_all_years[[list_id]]
  
  #reduce predictors using correlation metrics
  rf_models <- list()
  last_fit_metrics <- list()
  importance_plots <- list()
  importance_scores_year <- list()
  model_accuracy <- list() 
  pv_fits <- list()
  
  response_vars <- c("resin_birch", "black_spruce", "white_spruce", "black_cottonwood", "quaking_aspen")
  for (response in response_vars) {
    #split data
    raw_bands <- c("blue_1", "blue_2", "blue_3",
                   "green_1", "green_2", "green_3",
                   "red_1", "red_2", "red_3",
                   "nir_1", "nir_2", "nir_3",
                   "swir1_1", "swir1_2", "swir1_3",
                   "swir2_1", "swir2_2", "swir2_3")
    
    predictors <- setdiff(names(pv_dataframe), response_vars) #rm response vars
    predictors <- setdiff(predictors, raw_bands)
    pv_split <- initial_split(pv_dataframe %>% select(all_of(response), all_of(predictors)), 
                              prop = 0.85, strata = all_of(response)) 
    
    pv_train <- training(pv_split)
    pv_test <- testing(pv_split)
    
    
    #set formula
    formula <- as.formula(paste(response, "~", paste(predictors, collapse = "+")))
 
    #feature engineer and set up recipe
    rf_recipe <- recipe(formula = formula, data = pv_train) %>%
      step_nzv(all_predictors()) %>% #rm zero variance vars
      step_corr(all_numeric_predictors(), 
                threshold = 0.85, 
                use = "pairwise.complete.obs", 
                method = "pearson", 
                id = rand_id("corr"))
    
    #define models specs
    rf_spec <- 
      rand_forest(mtry = tune(), trees = 750) %>% 
      set_mode("regression") %>% 
      set_engine("randomForest")
    rf_spec_ranger <- 
      rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>% 
      set_mode("regression") %>% 
      set_engine("ranger", importance = "permutation")
    xgboost_spec <- 
      boost_tree(mtry = tune(), trees = 1000, learn_rate = tune()) %>% 
      set_mode("regression") %>% 
      set_engine("xgboost")
    
    #hyperparam tuning grids
    rf_grid <- grid_regular(
      mtry(range = c(5,15)),
      levels = 5)
    ranger_grid <- grid_regular(
      mtry(range = c(5,15)),
      min_n(range = c(2, 10)),
      trees(range = c(500,1500)),
      levels = 5)
    xgboost_grid <- grid_regular(
      mtry(range = c(5,15)),
      learn_rate(range = c(0.01, 0.1)),
      levels = 5)
    
    #model workflows
    workflow <- workflow() %>%
      add_recipe(rf_recipe) %>%
      add_model(rf_spec)
    ranger_workflow <- workflow() %>% 
      add_recipe(rf_recipe) %>% 
      add_model(rf_spec_ranger)
    xgboost_workflow <- workflow() %>% 
      add_recipe(rf_recipe) %>% 
      add_model(xgboost_spec)
    

    # resample and collect model metrics
    #set.seed(70684)
    set.seed(181330)
    pv_folds <- vfold_cv(pv_train, v = 10, strata = all_of(response))
    
    rf_tune_results <- tune_grid(
      workflow, 
      resamples = pv_folds, 
      grid = rf_grid, 
      metrics = metric_set(rmse, rsq, mae))
    
    ranger_tune_results <- tune_grid(
      ranger_workflow,
      resamples = pv_folds,
      grid = ranger_grid,
      metrics = metric_set(rmse, rsq, mae))
    
    xgboost_tune_results <- tune_grid(
      xgboost_workflow,
      resamples = pv_folds,
      grid = xgboost_grid,
      metrics = metric_set(rmse, rsq, mae))
    
    
    #select best performing model
    best_rf_params <- select_best(rf_tune_results, metric = "rmse")
    best_ranger_params <- select_best(ranger_tune_results, metric = "rmse")
    best_xgboost_params <- select_best(xgboost_tune_results, metric = "rmse")
    
    final_rf_workflow <- finalize_workflow(workflow, best_rf_params)
    final_ranger_workflow <- finalize_workflow(ranger_workflow, best_ranger_params)
    final_xgboost_workflow <- finalize_workflow(xgboost_workflow, best_xgboost_params)
    
    rf_fit <- last_fit(final_rf_workflow, pv_split)
    ranger_fit <- last_fit(final_ranger_workflow, pv_split)
    xgboost_fit <- last_fit(final_xgboost_workflow, pv_split)
    
    rf_metrics <- collect_metrics(rf_fit)
    ranger_metrics <- collect_metrics(ranger_fit)
    xgboost_metrics <- collect_metrics(xgboost_fit)
    
    year_chr <- as.character(year)
    print(paste0("rf rmse and r2:", response, year_chr, ":", rf_metrics$.estimate))
    print(paste0("ranger rmse and r2:", response, year_chr, ":", ranger_metrics$.estimate))
    print(paste0("xgb rmse and r2:", response, year_chr, ":", xgboost_metrics$.estimate))

    write.csv(rf_metrics, 
              paste0(out_dir_metrics, "Interior_Biomass_RF_Metrics_", 
                     response, "_", year_chr, "_Run1.csv"), row.names = FALSE)
    write.csv(ranger_metrics, 
          paste0(out_dir_metrics, "Interior_Biomass_RANGER_Metrics_", 
                 response, "_", year_chr, "_Run1.csv"), row.names = FALSE)
    write.csv(xgboost_metrics, 
          paste0(out_dir_metrics, "Interior_Biomass_XGB_Metrics_", 
                 response, "_", year_chr, "_Run1.csv"), row.names = FALSE)
    
    #plotting
    importance_plot <- vip(ranger_fit$.workflow[[1]]$fit, 
                           num_features = 16, geom = "col",
                           aesthetics = list(fill = "darkred")) +
                           labs(title = paste("RangerRF Importance", 
                                              response, year_chr)) +
                           theme_minimal()
    plot(importance_plot)
    # 
    # importance_scores <- randomForest::importance(rf_fit$fit)
    # importance_scores_df <- as.data.frame(importance_scores)
    # importance_scores_df$year <- year
    # importance_scores_df$response <- response
    
    # write.csv(importance_scores_df, 
    #           paste0("data/output/csv/cleaned/Biomass_RF_Model_Run_Results/Interior_Biomass_ImportanceScores_", 
    #                  response, "_", year_chr, "_Run1.csv"))
    # write.csv(rf_metrics, 
    #           paste0("data/output/csv/cleaned/Biomass_RF_Model_Run_Results/Interior_Biomass_RF_Metrics_", 
    #                  response, "_", year_chr, "_Run1.csv"))
    
    #store models and importance scores for each response var
    # importance_plots[[response]] <- importance_plot
    # importance_scores_year[[response]] <- importance_scores_df
    #model_accuracy[[response]] <- final_rf_fit
    # last_fit_metrics[[response]] <- metrics
    # rf_models[[response]] <- rf_tune
  
    
    # # spatial prediction here:
    # shortname <- substr(response, 5, nchar(response)) #remove bio.
    # prediction_map <- predict(pv_composites_all_bands[[list_id]], final_rf_fit) #make sure order matches
    # file_name <- paste0("data/output/raster/Dalton_BiomassPred_", shortname, "_", year_chr, ".tif")
    # writeRaster(prediction_map, file_name, overwrite = TRUE)
    # plot(prediction_map, main = paste0(as.character(shortname), year_chr))
    # print(summary(prediction_map))
    # print(paste0("prediction map saved for:", shortname, "year", year_chr))

    
    #clear cache
    rm(pv_split, pv_train, 
       pv_test, pv_folds, rf_tune_results, ranger_tune_results, xgboost_tune_results,
       rf_fit, ranger_fit, xgboost_fit)
    #rm(prediction_map)
    gc()
  }

  #store output for each year
  # rf_models_all_years[[list_id]] <- rf_models  
  # rf_model_metrics[[list_id]] <- last_fit_metrics
  # importance_plots_all_years[[list_id]] <- importance_plots
  # importance_scores_all_years[[list_id]] <- bind_rows(importance_scores_year)
  # model_accuracy_all_years[[list_id]] <- model_accuracy
  # pv_fits_all_years[[list_id]] <- pv_fits
}
#stopCluster(clus)
```

# Combine R-2 Values

```{r}
list_of_r2_files <- list.files(out_dir_metrics, pattern = "Interior_", full.names = TRUE)
file_to_df <- function(file){
  filename <- basename(file)
  model <- str_extract(filename, "RANGER|RF|XGB")
  year <- str_extract(filename, "\\d{4}")
  species <- str_extract(filename, "(?<=Metrics_)[^_]+_[^_]+")
  
  df <- read.csv(file)
  df$model <- model
  df$year <- year
  df$species <- species
  df <- df %>%
    select(-.config, -.estimator)
  return(df)
}
list_of_r2_dfs <- lapply(list_of_r2_files, file_to_df)
r2_df <- bind_rows(list_of_r2_dfs)
r2_df <- r2_df %>%
  select(-X)
r2_df$year <- as.numeric(r2_df$year)
#write.csv(r2_df, "E:/MS-Research/alaska/data/output/model_fits/Run1_All_Metrics.csv", row.names = FALSE)


#########
ggplot(r2_df %>% filter(.metric == "rsq"), aes(x = year, y = .estimate, color = model)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  facet_wrap(~ species, scales = "free_y") +
  labs(
    title = "R-squared (rsq) Over Time by Species and Model",
    x = "Year",
    y = "R-squared (rsq)",
    color = "Model"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5)
  )

```
